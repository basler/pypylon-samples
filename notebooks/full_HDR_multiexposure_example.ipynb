{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:49.049164Z",
     "start_time": "2025-06-02T22:01:49.045963Z"
    }
   },
   "source": [
    "from pypylon import pylon as py\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## This notebook demonstrates how to configure a Basler camera for HDR imaging using the sequencer mode.",
   "id": "c4bc9db23eaaddf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 1: Configure the camera and capture images",
   "id": "7441303f5b506f94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:49.058597Z",
     "start_time": "2025-06-02T22:01:49.052165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example Exposure times in microseconds\n",
    "exposure_times_us = [500, 5000, 50000, 500000]\n",
    "destination_folder = \"raw_image\"\n",
    "\n",
    "# ensure the destination folder exists\n",
    "Path(destination_folder).mkdir(parents=True, exist_ok=True)"
   ],
   "id": "1f8fa67a30f9597c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:50.061278Z",
     "start_time": "2025-06-02T22:01:49.072394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the Basler Pylon SDK to access the camera\n",
    "camera = py.InstantCamera(py.TlFactory.GetInstance().CreateFirstDevice())\n",
    "camera.Open()\n",
    "\n",
    "try:\n",
    "    # disable the sequencer mode if it is already active and enter configuration mode\n",
    "    camera.SequencerMode.Value = \"Off\"\n",
    "    camera.SequencerConfigurationMode.Value = \"On\"\n",
    "\n",
    "    # Set the exposure time for each sequencer set\n",
    "    for set_index, exposure_time in enumerate(exposure_times_us):\n",
    "        # Load the current sequencer set\n",
    "        camera.SequencerSetSelector.Value = set_index\n",
    "        camera.SequencerSetLoad.Execute()\n",
    "        # Set the exposure time for the current sequencer set\n",
    "        camera.ExposureTime.Value = exposure_time\n",
    "        # setup the path for the sequencer, return to the first set after the last one\n",
    "        camera.SequencerSetNext.Value = set_index + 1 if set_index < len(exposure_times_us) - 1 else 0\n",
    "        # Change the sequencer to next set after the beginning of the exposure\n",
    "        camera.SequencerTriggerSource.Value = \"ExposureStart\"\n",
    "        # save the sequencer set before configure the next one in the loop\n",
    "        camera.SequencerSetSave.Execute()\n",
    "\n",
    "    # Setup of the sequencer is done, quit configuration mode\n",
    "    camera.SequencerConfigurationMode.Value = \"Off\"\n",
    "except py.LogicalErrorException as error:\n",
    "    print(\"Camera does not support sequencer configuration mode.\")\n",
    "    camera.Close()\n",
    "    exit(1)"
   ],
   "id": "46d8983a7e12ae48",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:50.082561Z",
     "start_time": "2025-06-02T22:01:50.080001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# only mono images are supported by the example transformation,\n",
    "# but if you try this with a color camera, you have to disable color processing\n",
    "try:\n",
    "    camera.ColorSpace.Value = \"Off\"\n",
    "    camera.BalanceWhiteAuto.Value = \"Off\"\n",
    "except py.LogicalErrorException:\n",
    "    # The camera does not support color processing, so we can ignore this error\n",
    "    pass"
   ],
   "id": "efd87f83b6560513",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:50.410181Z",
     "start_time": "2025-06-02T22:01:50.096752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup the camera to use 12 Bit pixel format and linear image to avoid any gamma correction\n",
    "camera.PixelFormat.Value = \"Mono12\"\n",
    "camera.Gamma.Value = 1.0\n",
    "camera.ExposureAuto.Value = \"Off\"\n",
    "\n",
    "# use burst mode to grab all images with one (software) trigger\n",
    "camera.AcquisitionBurstFrameCount.Value = len(exposure_times_us)\n",
    "camera.TriggerSelector.Value = \"FrameBurstStart\"\n",
    "camera.TriggerMode.Value = \"On\"\n",
    "camera.TriggerSource.Value = \"Software\"\n",
    "\n",
    "# activate the sequencer mode\n",
    "camera.SequencerMode.Value = \"On\"\n",
    "\n",
    "# calculate the timeout for the grab operation,\n",
    "# in sequencer mode the camera will report the lowest fps based on the settings,\n",
    "# use this value plus a margin to avoid timeout errors\n",
    "timeout_ms = int(1000 / camera.BslResultingTransferFrameRate.Value + 1000)\n"
   ],
   "id": "e7b7b060f0a4dec2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:51.308120Z",
     "start_time": "2025-06-02T22:01:50.424808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# finally, start the camera grabbing process and trigger the burst\n",
    "camera.StartGrabbing(py.GrabStrategy_OneByOne)\n",
    "camera.ExecuteSoftwareTrigger()\n",
    "\n",
    "# grab the images and save them to disk\n",
    "py_image = py.PylonImage()\n",
    "for i in range(len(exposure_times_us)):\n",
    "    with camera.RetrieveResult(timeout_ms, py.TimeoutHandling_ThrowException) as grab_result:\n",
    "        if grab_result.GrabSucceeded():\n",
    "            py_image.AttachGrabResultBuffer(grab_result)\n",
    "            py_image.Save(imageFileFormat=py.ImageFileFormat_Tiff,\n",
    "                          filename=f\"raw_image/img_{exposure_times_us[i]}us.tiff\")\n",
    "        else:\n",
    "            print(f\"Error: {grab_result.ErrorCode} - {grab_result.ErrorDescription}\")"
   ],
   "id": "bd1945fdcb2c3e29",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:51.344071Z",
     "start_time": "2025-06-02T22:01:51.322213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# release the image and stop the camera\n",
    "py_image.Release()\n",
    "camera.StopGrabbing()\n",
    "camera.Close()"
   ],
   "id": "6f5f6566b2c205fc",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 2: Load the images and create an HDR image",
   "id": "2bb2bf14d4a3d7e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:51.359794Z",
     "start_time": "2025-06-02T22:01:51.357528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from pathlib import Path"
   ],
   "id": "eff51c9847296135",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:51.390061Z",
     "start_time": "2025-06-02T22:01:51.373789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 1: Find all TIFF images in the 'raw_image' folder ---\n",
    "image_dir = Path(destination_folder)\n",
    "image_paths = sorted(image_dir.glob(\"*.tif*\"))\n",
    "\n",
    "images = []\n",
    "exposures_us = []"
   ],
   "id": "c0d50f254f624dd5",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:51.864950Z",
     "start_time": "2025-06-02T22:01:51.403937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 2: Load images and extract exposure times from filenames ---\n",
    "for path in image_paths:\n",
    "    # Load 16-bit image\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {path}\")\n",
    "    img = (img >> 4)  #\n",
    "\n",
    "    images.append(img)\n",
    "\n",
    "    # Extract exposure time from filename (e.g. 'img_33000us.tiff')\n",
    "    match = re.search(r\"(\\d+)us\", path.name)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Filename does not contain exposure time: {path.name}\")\n",
    "    exposures_us.append(int(match.group(1)))\n",
    "\n",
    "print(f\"Loaded {len(images)} images with exposure times: {exposures_us}\")"
   ],
   "id": "c71616bfa70b117b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 images with exposure times: [500000, 50000, 5000, 500]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:52.618541Z",
     "start_time": "2025-06-02T22:01:51.880063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 3: Stack and normalize images to float32 in range [0, 1] ---\n",
    "ldr_stack = np.stack(images, axis=-1).astype(np.float32) / 4095.0\n",
    "exposure_times = np.array(exposures_us, dtype=np.float32) / 1e6  # Âµs to s"
   ],
   "id": "d4e632af3205a88f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:54.226956Z",
     "start_time": "2025-06-02T22:01:52.633316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 4: Define triangle weighting function to suppress over/underexposed pixels ---\n",
    "def weight_func(z):\n",
    "    return z * (1.0 - z)\n",
    "\n",
    "weights = weight_func(ldr_stack)\n",
    "weights[weights == 0] = 1e-4  # avoid divide-by-zero"
   ],
   "id": "c8bf9e315bf857a6",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:57.650091Z",
     "start_time": "2025-06-02T22:01:54.242756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Step 5: Compute HDR image as weighted radiance map ---\n",
    "hdr_numerator = np.sum(weights * ldr_stack / exposure_times.reshape((1, 1, -1)), axis=2)\n",
    "hdr_denominator = np.sum(weights, axis=2)\n",
    "hdr_denominator[hdr_denominator == 0] = 1e-4  # prevent division by zero\n",
    "hdr_image = hdr_numerator / hdr_denominator"
   ],
   "id": "13e4bfcc95243f22",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:58.016196Z",
     "start_time": "2025-06-02T22:01:57.664091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 6: Clean up invalid values (NaN, inf) ---\n",
    "hdr_image = np.nan_to_num(hdr_image, nan=0.0, posinf=1.0, neginf=0.0)"
   ],
   "id": "9d50295cdb36539c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:58.928854Z",
     "start_time": "2025-06-02T22:01:58.030188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 7: Convert grayscale HDR image to 3-channel format for OpenCV tonemap ---\n",
    "hdr_3ch = np.stack([hdr_image] * 3, axis=-1).astype(np.float32).copy()"
   ],
   "id": "7647478022410a5e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:01:58.957348Z",
     "start_time": "2025-06-02T22:01:58.944412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 8: Tonemap using OpenCV (Reinhard operator) ---\n",
    "tonemap = cv2.createTonemapReinhard(gamma=1.0, intensity=0.0, light_adapt=1.0, color_adapt=0.0)\n",
    "ldr_tonemapped = tonemap.process(hdr_3ch)\n",
    "ldr_tonemapped = np.nan_to_num(ldr_tonemapped, nan=0.0, posinf=1.0, neginf=0.0)"
   ],
   "id": "12b19ec39d221e7e",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\photo\\src\\tonemap.cpp:69: error: (-215:Assertion failed) _src.dims() == 2 && _src.type() == CV_32FC3 in function 'cv::TonemapImpl::process'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# --- Step 8: Tonemap using OpenCV (Reinhard operator) ---\u001B[39;00m\n\u001B[0;32m      2\u001B[0m tonemap \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcreateTonemapReinhard(gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m, intensity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, light_adapt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m, color_adapt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m ldr_tonemapped \u001B[38;5;241m=\u001B[39m \u001B[43mtonemap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhdr_3ch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m ldr_tonemapped \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(ldr_tonemapped, nan\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, posinf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m, neginf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m)\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\photo\\src\\tonemap.cpp:69: error: (-215:Assertion failed) _src.dims() == 2 && _src.type() == CV_32FC3 in function 'cv::TonemapImpl::process'\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Step 9: Scale to 8-bit image for saving or display ---\n",
    "ldr_8bit = (ldr_tonemapped * 255).clip(0, 255).astype(np.uint8)\n"
   ],
   "id": "5367661a5f54ba8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Step 10: Display and save the result ---\n",
    "cv2.imwrite(\"ldr_result.png\", ldr_8bit)\n",
    "#cv2.imshow(\"Tonemapped Image\", ldr_8bit)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ],
   "id": "19f05bd0241f814"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
